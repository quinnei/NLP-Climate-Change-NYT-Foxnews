{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257c817b",
   "metadata": {},
   "source": [
    "# Fox news\n",
    "\n",
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbc4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import time\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bd1e0",
   "metadata": {},
   "source": [
    "### I. From Fox news' `U.S`/`World`/`Science` categories, scrape <ins>climate-related</ins> news published in <ins>2018-2022</ins>\n",
    "\n",
    "#### a) Gather data from Fox news' *dynamic* website <br><br> b) Filter the results to only those that fall within our 5-year time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65478818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that generates the URLs of 3 sections where climate related news can be found\n",
    "\n",
    "def construct_URL(section):\n",
    "    base_URL = \"https://www.foxnews.com/category/\"\n",
    "    \n",
    "    if section == 'us' or section == 'world':\n",
    "        URL = base_URL + section + '/environment/climate-change'\n",
    "    elif section == 'science':\n",
    "        URL = base_URL + section + '/planet-earth/climate'\n",
    "    \n",
    "    return URL\n",
    "\n",
    "    \n",
    "# Define a function that extracts the title/abstract/date/section/URL of each article\n",
    "def extract_metadata(xpath_expression):\n",
    "    return response.xpath(xpath_expression).getall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3716f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the list of URLs where climate change-related news are posted\n",
    "foxnews_URLs = [construct_URL(\"us\"), construct_URL(\"world\"), construct_URL(\"science\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7dddd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE: Web scraping may be temporarily unsuccessful if 'breaking news' occasionally pops up on the website ###\n",
    "#### In case of error 'element click intercepted', you may want to add an if else statement to close the pop up table ###\n",
    "#### Alternatively, please try again once the pop up is taken down from the website ###\n",
    "\n",
    "### 1) Review & Access the webpage\n",
    "\n",
    "# Install webdriver\n",
    "service = ChromeService(ChromeDriverManager().install())\n",
    "\n",
    "# Create an instance of Chrome web driver\n",
    "driver = webdriver.Chrome(service = service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e6a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Successfully!\n",
      "Number of articles under Fox News' us category: 619\n",
      "\n",
      "Saved Successfully!\n",
      "Number of articles under Fox News' world category: 442\n",
      "\n",
      "Saved Successfully!\n",
      "Number of articles under Fox News' science category: 609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store search results for each category\n",
    "search_results = {\n",
    "    'us': [],\n",
    "    'world': [],\n",
    "    'science': []}\n",
    "\n",
    "# Navigate to/load the website (i.e. each climate category of Fox News)\n",
    "\n",
    "for URL in foxnews_URLs:\n",
    "    \n",
    "    driver.get(URL)\n",
    "    \n",
    "    # Allow 10 seconds of rest time   \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "    # Click 'Show More' multiple times, to expand all search results\n",
    "    i = 0\n",
    "\n",
    "    while i < 3000:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            element = wait.until(EC.visibility_of_element_located(\n",
    "                (By.XPATH, \"(//div[@class='button load-more js-load-more'])[1]/a\")))\n",
    "            element.click()\n",
    "            i += 1\n",
    "        except TimeoutException:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    # Retrieve & store the html source code\n",
    "    response = Selector(text = driver.page_source)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### 2) Parse the html source code\n",
    "\n",
    "    \n",
    "\n",
    "    # Extract the title/abstract/date/section/URL of each article\n",
    "    # Use the custom function:\n",
    "    titles = extract_metadata('//h4[@class=\"title\"]/a/text()')\n",
    "    abstracts = extract_metadata('//p[@class=\"dek\"]/a/text()')\n",
    "    dates = extract_metadata(\"//span[@class='time']/text()\")\n",
    "    sections = extract_metadata(\"//span[@class='eyebrow']/a/text()\")\n",
    "    urls = extract_metadata('//h4[@class=\"title\"]/a/@href')\n",
    "\n",
    "    # Make sure that the URL is in *full* html format.\n",
    "    urls = ['https://www.foxnews.com' + url for url in urls]\n",
    "\n",
    "\n",
    "\n",
    "    # Store search results from the *current page*\n",
    "    data_structure = zip(titles, abstracts, dates, sections, urls)\n",
    "\n",
    "    # for document, title, abstract, date, section, url in data_structure:\n",
    "    for title, abstract, date, section, url in data_structure:\n",
    "\n",
    "        # Split the URL by '/'.\n",
    "        # Then extract the article category (for indicating which dataframe the stored output refers to)\n",
    "        article_category = URL.split('/')[4]\n",
    "        \n",
    "        # Apply filtering conditions:\n",
    "        # a) Remove opinion pieces, videos, tweet posts and articles that fall outside of the date range\n",
    "        # b) Keep only news articles published between 2018 - 2022\n",
    "\n",
    "        if section not in ['OPINION', 'VIDEO', 'Live Coverage', 'Books'] and \\\n",
    "        date.endswith(('2018', '2019', '2020', '2021', '2022')):\n",
    "        \n",
    "            extracted_from_current_page = {\n",
    "                'title': title,\n",
    "                'abstract': abstract,\n",
    "                'date': date,\n",
    "                'section': section,\n",
    "                'url': url\n",
    "            }\n",
    "\n",
    "\n",
    "            # 3) Store metadata (results from the current page) as a data as a list of dictionary\n",
    "    \n",
    "            search_results[article_category].append(extracted_from_current_page)\n",
    "            \n",
    "    print(\"Saved Successfully!\")\n",
    "    print(f\"Number of articles under Fox News' {article_category} category: {len(search_results[article_category])}\\n\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "279aa1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the chrome window, once we've successfully saved all data\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ab6a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Eco activists Prince Harry, Meghan pictured leaving private jet on way to gala giving sustainability award',\n",
       "  'abstract': 'Royal couple Prince Harry and Meghan Markle, two outspoken environmental activists, were photographed departing a private jet in New York City this week.',\n",
       "  'date': 'December 7, 2022',\n",
       "  'section': 'Climate Change',\n",
       "  'url': 'https://www.foxnews.com/politics/eco-activists-prince-harry-meghan-pictured-leaving-private-jet-way-gala-giving-sustainability-award'},\n",
       " {'title': 'Alaska region sees record December heat, beating temperatures from late October to April',\n",
       "  'abstract': 'A community in Alaska is experiencing unusually warm weather in December. This month saw a new record by six degrees, which also beat temperatures between October and April.',\n",
       "  'date': 'December 6, 2022',\n",
       "  'section': 'Alaska',\n",
       "  'url': 'https://www.foxnews.com/us/alaska-region-sees-record-december-heat-beating-temperatures-late-october-april'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display metadata of the first 2 articles under the 'U.S.' climate category\n",
    "search_results['us'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62beea3",
   "metadata": {},
   "source": [
    "### II. Compile all search results from Fox news' three categories (`U.S`/`World`/`Science`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2642b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1644 climate-related articles that were published throughout 2018-2022.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eco activists Prince Harry, Meghan pictured le...</td>\n",
       "      <td>Royal couple Prince Harry and Meghan Markle, t...</td>\n",
       "      <td>December 7, 2022</td>\n",
       "      <td>us</td>\n",
       "      <td>https://www.foxnews.com/politics/eco-activists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska region sees record December heat, beati...</td>\n",
       "      <td>A community in Alaska is experiencing unusuall...</td>\n",
       "      <td>December 6, 2022</td>\n",
       "      <td>us</td>\n",
       "      <td>https://www.foxnews.com/us/alaska-region-sees-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rashida Tlaib, Ro Khanna join protests against...</td>\n",
       "      <td>Democratic Reps. Rashida Tlaib and Ro Khanna j...</td>\n",
       "      <td>December 6, 2022</td>\n",
       "      <td>us</td>\n",
       "      <td>https://www.foxnews.com/politics/rashida-tlaib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semafor climate editor exits after complaining...</td>\n",
       "      <td>Bill Spindle, climate editor of the recently-l...</td>\n",
       "      <td>December 6, 2022</td>\n",
       "      <td>us</td>\n",
       "      <td>https://www.foxnews.com/media/semafor-climate-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Left ripped for pushing nightmarish climate na...</td>\n",
       "      <td>'The Five' co-hosts discuss how the left's cli...</td>\n",
       "      <td>December 6, 2022</td>\n",
       "      <td>us</td>\n",
       "      <td>https://www.foxnews.com/media/left-ripped-push...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Eco activists Prince Harry, Meghan pictured le...   \n",
       "1  Alaska region sees record December heat, beati...   \n",
       "2  Rashida Tlaib, Ro Khanna join protests against...   \n",
       "3  Semafor climate editor exits after complaining...   \n",
       "4  Left ripped for pushing nightmarish climate na...   \n",
       "\n",
       "                                            abstract              date  \\\n",
       "0  Royal couple Prince Harry and Meghan Markle, t...  December 7, 2022   \n",
       "1  A community in Alaska is experiencing unusuall...  December 6, 2022   \n",
       "2  Democratic Reps. Rashida Tlaib and Ro Khanna j...  December 6, 2022   \n",
       "3  Bill Spindle, climate editor of the recently-l...  December 6, 2022   \n",
       "4  'The Five' co-hosts discuss how the left's cli...  December 6, 2022   \n",
       "\n",
       "  section                                                url  \n",
       "0      us  https://www.foxnews.com/politics/eco-activists...  \n",
       "1      us  https://www.foxnews.com/us/alaska-region-sees-...  \n",
       "2      us  https://www.foxnews.com/politics/rashida-tlaib...  \n",
       "3      us  https://www.foxnews.com/media/semafor-climate-...  \n",
       "4      us  https://www.foxnews.com/media/left-ripped-push...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all metadata about climate-related articles from all 3 URLs\n",
    "metadata_from_all_news_categories = []\n",
    "\n",
    "# Loop through each key (news category, i.e. US/World/Science) in search_results\n",
    "for news_category, metadata_in_list in search_results.items():\n",
    "    \n",
    "    # Convert the metadata scraped from the given news category (-> a list of dictionary) to a dataframe\n",
    "    temp_df = pd.DataFrame(metadata_in_list)\n",
    "    \n",
    "    # Add a new column indicating the section (i.e. news category)\n",
    "    temp_df['section'] = news_category\n",
    "    \n",
    "    # Append metadata scraped from the given news category\n",
    "    metadata_from_all_news_categories.append(temp_df)\n",
    "\n",
    "# Concatenate all metadata collected from the 3 URLS\n",
    "# Remove any redundant news articles across the 3 URLs\n",
    "foxnews = pd.concat(metadata_from_all_news_categories, ignore_index = True).drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "\n",
    "print(f\"There are {foxnews.shape[0]} climate-related articles that were published throughout 2018-2022.\")\n",
    "\n",
    "foxnews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ac115",
   "metadata": {},
   "source": [
    "### III. Store the data as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399dde02",
   "metadata": {},
   "outputs": [],
   "source": [
    "foxnews.to_csv(\"./1_Data/Foxnews.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
